{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"colab":{"name":"Day097_Keras_CNN_vs_DNN.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"qAsKB5xRZNHo"},"source":["import keras\n","from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import RMSprop, Adam\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_l0aZGguZNHr","executionInfo":{"status":"ok","timestamp":1595390063826,"user_tz":-480,"elapsed":2425,"user":{"displayName":"李偉傑","photoUrl":"","userId":"09976082193714070002"}},"outputId":"ac6affc7-46ed-4fb2-8239-7df2698fc407","colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["batch_size = 256 # batch 的大小，如果出現 OOM error，請降低這個值\n","num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n","epochs = 10 # 訓練的 epochs 數量\n","\n","# 讀取資料並檢視\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jFFNu7xIZNHt"},"source":["## 首先我們使用一般的 DNN (MLP) 來訓練\n","由於 DNN 只能輸入一維的資料，我們要先將影像進行攤平，若 (50000, 32, 32, 3) 的影像，攤平後會變成 (50000, 32*32*3) = (50000, 3072)"]},{"cell_type":"code","metadata":{"id":"tB2O1PUXZNHu","executionInfo":{"status":"ok","timestamp":1595390063826,"user_tz":-480,"elapsed":2415,"user":{"displayName":"李偉傑","photoUrl":"","userId":"09976082193714070002"}},"outputId":"ea6c89d1-bad0-4d59-c877-b7dfef32cbde","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# 將資料攤平成一維資料\n","x_train = x_train.reshape(50000, 3072) \n","x_test = x_test.reshape(10000, 3072)\n","\n","# 將資料變為 float32 並標準化\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VXjDx-4tZNHw","executionInfo":{"status":"ok","timestamp":1595390076725,"user_tz":-480,"elapsed":15306,"user":{"displayName":"李偉傑","photoUrl":"","userId":"09976082193714070002"}},"outputId":"d4bddf63-0adb-48b0-b225-a09bcd4d9ae9","colab":{"base_uri":"https://localhost:8080/","height":745}},"source":["model = Sequential()\n","model.add(Dense(512, activation='relu', input_shape=(3072,)))\n","model.add(Dropout(0.2))\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=RMSprop(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_16 (Dense)             (None, 512)               1573376   \n","_________________________________________________________________\n","dropout_16 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 512)               262656    \n","_________________________________________________________________\n","dropout_17 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 10)                5130      \n","=================================================================\n","Total params: 1,841,162\n","Trainable params: 1,841,162\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/10\n","50000/50000 [==============================] - 1s 28us/step - loss: 2.2853 - accuracy: 0.2202 - val_loss: 1.8898 - val_accuracy: 0.3019\n","Epoch 2/10\n","50000/50000 [==============================] - 1s 24us/step - loss: 1.9144 - accuracy: 0.3083 - val_loss: 1.7817 - val_accuracy: 0.3522\n","Epoch 3/10\n","50000/50000 [==============================] - 1s 23us/step - loss: 1.8283 - accuracy: 0.3432 - val_loss: 1.7619 - val_accuracy: 0.3625\n","Epoch 4/10\n","50000/50000 [==============================] - 1s 24us/step - loss: 1.7706 - accuracy: 0.3650 - val_loss: 1.7412 - val_accuracy: 0.3604\n","Epoch 5/10\n","50000/50000 [==============================] - 1s 23us/step - loss: 1.7280 - accuracy: 0.3804 - val_loss: 1.8341 - val_accuracy: 0.3669\n","Epoch 6/10\n","50000/50000 [==============================] - 1s 23us/step - loss: 1.6930 - accuracy: 0.3949 - val_loss: 1.6980 - val_accuracy: 0.3998\n","Epoch 7/10\n","50000/50000 [==============================] - 1s 23us/step - loss: 1.6610 - accuracy: 0.4088 - val_loss: 1.7091 - val_accuracy: 0.3745\n","Epoch 8/10\n","50000/50000 [==============================] - 1s 23us/step - loss: 1.6452 - accuracy: 0.4139 - val_loss: 1.6999 - val_accuracy: 0.3982\n","Epoch 9/10\n","50000/50000 [==============================] - 1s 23us/step - loss: 1.6209 - accuracy: 0.4229 - val_loss: 1.6122 - val_accuracy: 0.4093\n","Epoch 10/10\n","50000/50000 [==============================] - 1s 23us/step - loss: 1.6045 - accuracy: 0.4285 - val_loss: 1.5943 - val_accuracy: 0.4420\n","Test loss: 1.594265796661377\n","Test accuracy: 0.44200000166893005\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ipDAWAY_ZNHy"},"source":["## 接下來我們使用 CNN 來訓練神經網路\n","CNN 的原理非常適合處理影像類的資料，就讓我們來看看，同樣的訓練條件，CNN 是否顯著優於 DNN 呢?"]},{"cell_type":"code","metadata":{"id":"m2pRlOrJZNHy","executionInfo":{"status":"ok","timestamp":1595390077892,"user_tz":-480,"elapsed":16464,"user":{"displayName":"李偉傑","photoUrl":"","userId":"09976082193714070002"}},"outputId":"00527897-3f36-47d3-e0c4-96c0cd76de8e","colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RYp7Qp8NZNH0","executionInfo":{"status":"ok","timestamp":1595390124356,"user_tz":-480,"elapsed":62918,"user":{"displayName":"李偉傑","photoUrl":"","userId":"09976082193714070002"}},"outputId":"0b53de20-7ab7-4d2c-91bc-01b8cf912790","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=RMSprop(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_13 (Conv2D)           (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","activation_19 (Activation)   (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_14 (Conv2D)           (None, 30, 30, 32)        9248      \n","_________________________________________________________________\n","activation_20 (Activation)   (None, 30, 30, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","dropout_18 (Dropout)         (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","conv2d_15 (Conv2D)           (None, 15, 15, 64)        18496     \n","_________________________________________________________________\n","activation_21 (Activation)   (None, 15, 15, 64)        0         \n","_________________________________________________________________\n","conv2d_16 (Conv2D)           (None, 13, 13, 64)        36928     \n","_________________________________________________________________\n","activation_22 (Activation)   (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_8 (MaxPooling2 (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","dropout_19 (Dropout)         (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 2304)              0         \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 512)               1180160   \n","_________________________________________________________________\n","activation_23 (Activation)   (None, 512)               0         \n","_________________________________________________________________\n","dropout_20 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_20 (Dense)             (None, 10)                5130      \n","_________________________________________________________________\n","activation_24 (Activation)   (None, 10)                0         \n","=================================================================\n","Total params: 1,250,858\n","Trainable params: 1,250,858\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/10\n","50000/50000 [==============================] - 5s 101us/step - loss: 1.8928 - accuracy: 0.3162 - val_loss: 1.7149 - val_accuracy: 0.3817\n","Epoch 2/10\n","50000/50000 [==============================] - 4s 89us/step - loss: 1.4722 - accuracy: 0.4785 - val_loss: 1.3855 - val_accuracy: 0.4931\n","Epoch 3/10\n","50000/50000 [==============================] - 4s 89us/step - loss: 1.2796 - accuracy: 0.5500 - val_loss: 1.2389 - val_accuracy: 0.5630\n","Epoch 4/10\n","50000/50000 [==============================] - 4s 90us/step - loss: 1.1303 - accuracy: 0.6055 - val_loss: 1.0466 - val_accuracy: 0.6312\n","Epoch 5/10\n","50000/50000 [==============================] - 5s 90us/step - loss: 1.0244 - accuracy: 0.6429 - val_loss: 0.9959 - val_accuracy: 0.6534\n","Epoch 6/10\n","50000/50000 [==============================] - 5s 90us/step - loss: 0.9405 - accuracy: 0.6723 - val_loss: 1.0386 - val_accuracy: 0.6344\n","Epoch 7/10\n","50000/50000 [==============================] - 5s 90us/step - loss: 0.8690 - accuracy: 0.6960 - val_loss: 0.9236 - val_accuracy: 0.6771\n","Epoch 8/10\n","50000/50000 [==============================] - 5s 90us/step - loss: 0.8082 - accuracy: 0.7195 - val_loss: 1.0007 - val_accuracy: 0.6693\n","Epoch 9/10\n","50000/50000 [==============================] - 4s 89us/step - loss: 0.7628 - accuracy: 0.7331 - val_loss: 0.8855 - val_accuracy: 0.6840\n","Epoch 10/10\n","50000/50000 [==============================] - 4s 90us/step - loss: 0.7194 - accuracy: 0.7505 - val_loss: 0.7556 - val_accuracy: 0.7412\n","Test loss: 0.7556115198612213\n","Test accuracy: 0.7411999702453613\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c-EZdiwaZNH2"},"source":["## 同樣運算 10 個 epochs，但 CNN 在 test data 的準確率顯著優於 DNN!"]},{"cell_type":"markdown","metadata":{"id":"AcqdcvJxZNH2"},"source":["## 作業\n","1. 請試著調整各個超參數，並說明那些超參數對於結果有明顯的影響? batch_size\n","2. CNN 與 DNN 哪個模型的參數數量比較多? 造成參數的數量不同的原因在哪? DNN比較多 CNN只擷取特徵，使得進入全連接層資料量較少，導致總體參數相對較少"]}]}